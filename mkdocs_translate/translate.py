import deepl
import errno
import glob
import logging
import os
import pkgutil
import re
import requests
import subprocess
import yaml

from mkdocs_translate import __app_name__, __version__

logger = logging.getLogger(__app_name__)

# global configuration setup by cli._config_callback
config = {}
docs_folder = None
rst_folder = None
upload_folder = None
convert_folder = None
download_folder = None
anchor_file = None

anchors = {}
docs_folder = None

md_extensions_to = 'markdown+definition_lists+fenced_divs+backtick_code_blocks+fenced_code_attributes-simple_tables+pipe_tables'
md_extensions_from = 'markdown+definition_lists+fenced_divs+backtick_code_blocks+fenced_code_attributes+pipe_tables'

#
# CLI SUPPORT AND CONFIGURATION
#
def load_auth() -> str:
   """
    Load the authentication token for Deepl REST API.

    This function retrieves the Deepl authentication token from the
    environmental variable 'DEEPL_AUTH'. If the variable is not set,
    a ValueError is raised.

    Returns:
    str: The Deepl authentication token.

    Raises:
    ValueError: If the 'DEEPL_AUTH' environmental variable is not set.
   """
   AUTH = os.getenv('DEEPL_AUTH')
   if not AUTH:
      raise ValueError('Environmental variable DEEPL_AUTH required for translate with Deepl REST API')

   return AUTH

def load_config(override_path: str) -> dict:
    """
    Load the configuration settings.

    This function reads the configuration settings either from the specified
    override file or, if no override file is provided, from the default
    configuration file included with the 'mkdocs_translate' package.

    Parameters:
    - override_path (str): The path to the override configuration file. If
      provided, the function reads configuration settings from this file.

    Returns:
    dict: A dictionary containing the configuration settings.

    Notes:
    - If 'override_path' is provided, the function reads and returns the
      configuration from the specified file.
    - If 'override_path' is not provided, the function reads and returns the
      default configuration from the 'config.yml' file included with the
      'mkdocs_translate' package.

    Raises:
    FileNotFoundError: If 'override_path' is provided, but the file does not exist.
    yaml.YAMLError: If there is an issue parsing the YAML content.
    """
    if override_path:
        # override configuration
        with open(override_path, 'r') as file:
            text = file.read()
            return yaml.safe_load(text)
    else:
        # default configuration
        raw = pkgutil.get_data('mkdocs_translate', "config.yml")
        return yaml.safe_load(raw.decode('utf-8'))


def init_config(override_path: str) -> None:
   """
    Initialize configuration settings.

    This function initializes global variables related to the configuration
    settings. It loads the configuration using the provided override file
    path or defaults to the configuration included with the 'mkdocs_translate'
    package. It also constructs file paths based on the loaded configuration.

    Parameters:
    - override_path (str): The path to the override configuration file. If
      provided, the function loads configuration settings from this file.

    Returns:
    None: This function does not return a value.

    Notes:
    - The global variables 'config', 'docs_folder', 'upload_folder',
      'convert_folder', 'download_folder', 'rst_folder', and 'anchor_file'
      are initialized and made accessible globally after calling this function.

    - If 'override_path' is provided, the function loads the configuration
      from the specified file. Otherwise, it loads the default configuration
      from the 'config.yml' file included with the 'mkdocs_translate' package.

    - The file paths for 'docs_folder', 'upload_folder', 'convert_folder',
      'download_folder', and 'anchor_file' are constructed based on the loaded
      configuration.

    - The function logs debug information, including the configured paths.

   """
   global config
   global docs_folder
   global upload_folder
   global convert_folder
   global download_folder
   global rst_folder
   global anchor_file

   config = load_config(override_path)

   docs_folder = os.path.join(config['project_folder'],config['docs_folder'])
   upload_folder = os.path.join(config['project_folder'],config['build_folder'],config['upload_folder'])
   convert_folder = os.path.join(config['project_folder'],config['build_folder'],config['convert_folder'])
   download_folder = os.path.join(config['project_folder'],config['build_folder'],config['download_folder'])
   anchor_file = os.path.join(docs_folder,config['anchor_file'])

   rst_folder = docs_folder
   if 'rst_folder' in config:
      rst_folder = config['rst_folder']

   if not os.path.exists(docs_folder):
      logger.debug(f"The docs folder does not exist at location: {docs_folder}")
      #raise FileNotFoundError(errno.ENOENT, f"The docs folder does not exist at location:", docs_folder)

   if not os.path.exists(rst_folder):
      logger.debug(f"The rst folder does not exist at location: {rst_folder}")
      #raise FileNotFoundError(errno.ENOENT, f"The rst folder does not exist at location:", rst_folder)

   logger.debug('--- start configuration ---')
   logger.debug('  mkdocs: %s',docs_folder)
   logger.debug('  sphinx: %s',rst_folder)
   logger.debug('  upload: %s',upload_folder)
   logger.debug('download: %s',download_folder)
   logger.debug('    docs: %s',docs_folder)
   logger.debug(' anchors: %s',anchor_file)
   logger.debug('--- end configuration ---')
   return

def load_anchors(anchor_txt:str) -> dict[str,str]:
   """
    Load anchors from an anchor definition file.

    This function reads an anchor definition file, where each line contains
    an anchor and its corresponding path separated by '='. The anchors and paths
    are then stored in a dictionary.

    Parameters:
    - anchor_txt (str): The path to the anchor definition file.

    Returns:
    dict[str, str]: A dictionary where keys are anchors and values are paths.

    Raises:
    FileNotFoundError: If the anchor definition file does not exist.
   """
   if not os.path.exists(anchor_txt):
      logger.warning("Anchors definition file not avaialble - to creae run: python3 -m translate index")
      raise FileNotFoundError(errno.ENOENT, f"anchors definition file does not exist at location:", anchor_txt)

   index = {}
   with open(anchor_txt,'r') as file:
      for line in file:
         if '=' in line:
            (anchor,path) = line.split('=',1)
            index[anchor] = path[0:-1]

   return index

def init_anchors():
    global anchors
    global anchor_file
    anchors = load_anchors(anchor_file)
    logging.debug("anchors loaded:"+str(len(anchors)))


def collect_path(path: str, extension: str) -> list[str]:
    """
    Collect file paths based on a specified path and file extension.

    This function collects file paths based on the given path and file extension.
    If the provided path contains '*', it uses globbing to find matching files
    recursively with the specified extension. If the path does not contain '*',
    it checks if the file at the specified path has the specified extension.
    If the path is a single file the extension should match.

    Parameters:
    - path (str): The path or pattern to search for files.
    - extension (str): The file extension to filter the collected files.

    Returns:
    list[str]: A list of file paths that match the specified criteria.
    """
    files = []
    if '*' in path:
      for file in glob.glob(path,recursive = True):
         if file.endswith('.'+extension):
           files.append(file)
    else:
      if path.endswith('.'+extension):
        files.append(path)

    return files

def collect_paths(paths: list[str], extension: str) -> list[str]:
   """
   Collect files with a specified extension from a list of paths.

   This function collects file paths based on a list of paths and a specified
   file extension. For each path in the list, it uses the `collect_path` function
   to gather files with the given extension.

   Parameters:
   - paths (list[str]): A list of paths to search for files.
   - extension (str): The file extension to filter the collected files.

   Returns:
   list[str]: A list of file paths that match the specified criteria.
   See Also:
    - `collect_path`: A function used to collect files based on a single path.
   """
   files = []

   for path in paths:
      files.extend( collect_path(path,extension) )

   return files

#
# RST INDEX MANAGEMENT AND USE
#
def index_rst(base_path: str, rst_file: str) -> str:
   """
   Scan through rst_file producing doc and ref indexs
   Parameters:
   - base_path (str): The base path used for constructing relative paths.
   - rst_file (str): The path to the RST file to be scanned.

   Returns:
   str: The generated index as a string.

   Raises:
   FileNotFoundError: If the base_path or rst_file does not exist.
   """
   if not os.path.exists(base_path):
      raise FileNotFoundError(errno.ENOENT, f"RST base_path does not exist at location: {base_path}")

   common_path = os.path.commonpath([base_path,rst_file])
   if common_path != base_path:
      raise FileNotFoundError(errno.ENOENT, f"RST base_path '{base_path}' does not contain rst_file: '{rst_file}'")

   with open(rst_file, 'r') as file:
      text = file.read()

   relative_path = rst_file[len(base_path):]
   doc = relative_path
   ref = None
   heading = None
   index = ''

   with open(rst_file, 'r') as file:
      text = file.read()

   lines = text.splitlines()

   for i in range(0,len(lines)):
      line = lines[i]
      if len(line) == 0:
         continue

      if ref:
         heading = scan_heading(i,lines)
         if heading:
               logging.debug(" +- heading:"+heading)
               anchor = ref
               if doc:
                  # reference to doc heading, no need for anchor
                  index += ref + '=' + relative_path + "\n"
               else:
                  index += ref + '=' + relative_path + '#' + ref + "\n"
               index += ref + '.title=' + heading + "\n"
               ref = None

      if doc:
         heading = scan_heading(i,lines)
         if heading:
               logging.debug(" +- page:"+heading)
               index += doc + '=' + relative_path + "\n"
               index += doc + '.title=' + heading + "\n"
               doc = None

      match = re.search(r"^.. _((\w|.|-)*):$", line)
      if match:
         if ref:
               logging.warning("reference "+ref+" defined without a heading, skipped")

         ref = match.group(1)
         logging.debug(" |   ref:"+ref)

   return index

def scan_heading(index: int, lines: list[str] ) -> str:
    """
    Detect and return headline

    @return headline, or None
    """
    # Scan line by line for references and headings
    # # with overline, for parts
    h1 = '#############################################################################################################'
    # * with overline, for chapters
    h2 = '*************************************************************************************************************'
    # =, for sections
    h3 = '============================================================================================================='
    # -, for subsections
    h4 = '-------------------------------------------------------------------------------------------------------------'
    # ^, for subsubsections
    h5 = '^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^'
    # “, for paragraphs
    h6 = '"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""'
    h7 = "`````````````````````````````````````````````````````````````````````````````````````````````````````````````"
    h8 = "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
    h9 = "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''"
    if index >= len(lines)-1:
       return None # last line cannot be a heading

    line = lines[index]
    line_length = len(line)
    under = lines[index+1]
    under_length = len(under)

    if under_length < line_length:
       return None # not a heading

    if under == h1[0:under_length] or \
       under == h2[0:under_length] or \
       under == h3[0:under_length] or \
       under == h4[0:under_length] or \
       under == h5[0:under_length] or \
       under == h6[0:under_length] or \
       under == h7[0:under_length] or \
       under == h8[0:under_length] or \
       under == h9[0:under_length]:

       return line

    return None

def _doc_title(rst_path: str, doc_link: str) -> str:
   """
   Create a label title, based on a documentation link (using on anchors.txt index)
   """
   resolved_path = _doc_location(rst_path,doc_link)
   # example:
   #   /install-guide/loading-samples.rst=/install-guide/loading-samples.rst
   #   /install-guide/loading-samples.rst.title=Loading templates and sample data
   title_key = resolved_path+'.rst.title'
   if title_key in anchors:
       return anchors[title_key]
   else:
       label = _label(doc_link)
       logger.warning("broken doc '"+doc_link+"' title:"+label)
       return label

def _doc_location(rst_path: str, doc_link: str) ->  str:
    """
    Determines absolute path location for link, relative to provided path.

    Do not use as is, mkdocs only works with relative links

    :param rst_path: path of rst file providing the documentation link
    :param doc_link: documentation link (may be absolute or relative)
    :return: absolute path, indicating location relative to docs folder. Used for looking up title.
    """
    if doc_link.startswith("/"):
        return doc_link
    else:
        dir = os.path.dirname(rst_path)
        link_path = os.path.join(dir, doc_link)
        location = os.path.relpath(link_path, docs_folder)
        return '/'+location

def _label(link: str) -> str:
   """
   Create a default label, based on a doc link or reference.
   """
   label = link.replace('.rst','')
   label = label.replace('.md','')
   label = label.replace('/index', '')
   label = label.replace('-', ' ')
   label = label.replace('_', ' ')
   label = label.replace('/', ' ')
   label = label.title()

   return label

def _ref_title(reference: str) -> str:
    """
    Determines title for reference (using on anchors.txt index)
    :param reference: reference to document or heading
    :return: title for reference
    """
    title_lookup = reference+".title"

    if title_lookup in anchors:
       return anchors[title_lookup]
    else:
       label = _label(reference)
       logger.warning("broken reference '"+reference+"' title:"+label)
       return label

def _ref_location(reference: str) ->  str:
    """
    Determines absolute path#anchor for reference (using on anchors.txt index)
    :param reference: reference to document or heading
    :return: absolute path, indicating location relative to docs folder. Used to determine a relative path.
    """
    if reference in anchors:
       return anchors[reference]
    else:
       link = reference+"-broken.rst"
       logger.warning("broken reference '"+reference+"' link:"+link)
       return link

def _ref_path(rst_path: str, reference: str) ->  str:
    """
    Generate a relative link for the provided reference.
    """
    logging.debug("ref: "+reference)
    ref_location = _ref_location(reference)

    rst_location = os.path.relpath(os.path.dirname(rst_path),docs_folder)
    if ref_location.startswith("/"):
        ref_location = ref_location[1:]

    logging.debug("   reference: "+rst_location)
    logging.debug("    absolute: "+ref_location)

    link = os.path.relpath(ref_location,rst_location)

    logging.debug("    relative: "+link)
    return link


#
# RST PANDOC CONVERSION
#
def convert_rst(rst_file: str) -> str:
    """
    Use pandoc to convert rich-structured-text file to markdown file for mkdocs
    :param md_file: Markdown file path
    :return: markdown file path
    """
    if not os.path.exists(rst_file):
       raise FileNotFoundError(errno.ENOENT, f"RST file does not exist at location:", rst_file)

    if rst_file[-4:] != '.rst':
       raise FileNotFoundError(errno.ENOENT, f"Rich-structued-text 'rst' extension required:", rst_file)

    # file we are generating
    md_file = rst_file.replace(".txt",".md")
    md_file = md_file.replace(".rst",".md")

    # temp file for processing
    md_tmp_file = re.sub("^docs/",convert_folder+'/', rst_file)
    md_tmp_file = md_tmp_file.replace(".txt",".md")
    md_tmp_file = md_tmp_file.replace(".rst",".md")
    md_tmp_file = md_tmp_file.replace(".md",".tmp.md")

    convert_directory = os.path.dirname(md_tmp_file)
    if not os.path.exists(convert_directory):
       logger.info("Creating conversion directory '"+convert_directory+"'")
       os.makedirs(convert_directory)

    rst_prep = re.sub(r"\.md",r".prep.rst", md_tmp_file)

    logging.debug("Preprocessing '"+rst_file+"' to '"+rst_prep+"'")
    preprocess_rst(rst_file,rst_prep)

    logging.debug("Converting '"+rst_prep+"' to '"+md_tmp_file+"'")

    completed = subprocess.run(["pandoc",
#      "--verbose",
       "--from", "rst",
       "--to",md_extensions_to,
       "--wrap=none",
       "--eol=lf",
       "-o", md_tmp_file,
       rst_prep
    ])
    if completed.returncode != 0:
        print(completed)

    if not os.path.exists(md_tmp_file):
       raise FileNotFoundError(errno.ENOENT, f"Pandoc did not create md file:", md_tmp_file)

    logging.debug("Preprocessing '"+md_tmp_file+"' to '"+md_file+"'")
    postprocess_rst_markdown(md_tmp_file, md_file)
    if not os.path.exists(md_file):
      raise FileNotFoundError(errno.ENOENT, f"Did not create postprocessed md file:", md_file)

    return md_file

def preprocess_rst(rst_file:str, rst_prep: str) -> str:
    """
    Pre-process rst files to simplify sphinx-build directives for pandoc conversion
    """
    with open(rst_file, 'r') as file:
        text = file.read()

    # process toc_tree directive into a list of links
    if '.. toctree::' in text:
        text = _preprocess_rst_toctree(rst_file,text)

    if ':doc:' in text:
        text = _preprocess_rst_doc(rst_file,text)

    if ':ref:' in text:
        text = _preprocess_rst_ref(rst_file,text)

    if '.. figure::' in text:
        text = _preprocess_rst_figure(rst_file,text)
    
    # strip unsupported things
    if '.. index::' in text:
        text = _preprocess_rst_strip(rst_file,text,'index')
    if '.. contents::' in text:
        text = _preprocess_rst_strip(rst_file,text,'contents')
    
    # gui-label and menuselection represented: **Cancel**
    text = re.sub(
        r":guilabel:`(.*)`",
        r":**\1**",
        text,
        flags=re.MULTILINE
    )
    text = re.sub(
        r":menuselection:`(.*)`",
        r"**\1**",
        text,
        flags=re.MULTILINE
    )

    # command represented: ***mkdir***
    text = re.sub(
        r":command:`(.*?)`",
        r"***\1***",
        text,
        flags=re.MULTILINE
    )

    # file path represented: **`file`**
    text = re.sub(
        r":file:`(.*?)`",
        r"**`\1`**",
        text,
        flags=re.MULTILINE
    )

    # kbd represented with +++ by mkdocs
    text = re.sub(
        r":kbd:`(.*?)`",
        r"+++\1+++",
        text,
        flags=re.MULTILINE
    )

    # very simple literals: `some text` should use ``some text``
    text = re.sub(
        r"(\s)`(\w|\s)*([^`])`([^`])",
        r"\1``\2\3``\4",
        text,
        flags=re.MULTILINE
    )
    # rst_epilog stuff from config.py
    text = text.replace("|project_name|","GeoNetwork")
    text = text.replace("|jdbc.properties|",r"**`WEB-INF/config-db/jdbc.properties`**")
    text = text.replace("|config.node.folder|",r"**`WEB-INF/config-db/jdbc.properties`**")
    text = text.replace("|web.xml|",r"**`WEB-INF/web.xml`**")
    text = text.replace("|default.node|",r"`srv`")
    text = text.replace("|default.node.config.file|",r"**`WEB-INF/config-node/srv.xml`**")
    text = text.replace("|default.node|",r"`srv`")
    text = text.replace("|install.homepage|",r"`http://localhost:8080/geonetwork`")

    with open(rst_prep,'w') as rst:
        rst.write(text)

def _preprocess_rst_doc(path: str, text: str) -> str:
   """
   Preprocess rst content replacing doc references with links.
   """
   global anchors


   # doc links processed in order from most to least complicated

   # :doc:`normal <../folder/index.rst>`
   # :doc:`normal <link.rst>`
   # :doc:`normal <link>`
   # `normal <../folder/index.rst>`
   # `normal <link.rst>`
   # `normal <link.rst>`
   text = re.sub(
       r":doc:`(.+?) <(.+?)(\.rst)?>`",
       r"`\1 <\2.rst>`_",
       text,
       flags=re.MULTILINE
   )

   # :doc:`../folder/index.rst`
   # :doc:`simple.rst`
   # `title <../folder/index.rst>`_
   # `title <simple.rst>`_
   document_reference = re.compile(r":doc:`((\w|-|_)*?)(\.rst)?`")
   text = document_reference.sub(
       lambda match: "`"+_doc_title(path, match.group(1))+" <"+match.group(1)+".rst>`_",
       text
   )
   return text

def _preprocess_rst_ref(path: str, text: str) -> str:
   """
   Preprocess rst content replacing ref references with links.
   """
   # ref links processed in order from most to least complicated
   # :ref:`normal <link>`
   named_reference = re.compile(r":ref:`(.*) <((\w|-)*)>`")
   text = named_reference.sub(
       lambda match: "`"+match.group(1)+" <"+_ref_path(path,match.group(2))+">`_",
       text
   )

   # :ref:`simple`
   simple_reference = re.compile(r":ref:`((\w|-)*)\`")
   text = simple_reference.sub(
       lambda match: "`"+_ref_title(match.group(1))+" <"+_ref_path(path,match.group(1))+">`_",
       text
   )

   return text

def _preprocess_rst_toctree(path: str, text: str) -> str:
   """
   scan document for toctree directives to process
   """
   toctree = None
   process = ''
   for line in text.splitlines():
       if '.. toctree::' == line:
          # directive started
          toctree = ''
          continue

       if toctree != None:
          if len(line.strip()) == 0:
             continue
          if line.strip()[0:1] == ':':
             continue
          if line[0:3] == '   ':
             # processing directive
             link = line.strip().replace(".rst","")
             label = _doc_title(path,link)
             toctree += f"* `{label} <{link}.rst>`__\n"
          else:
             # end directive
             process += toctree + '\n'
             process += line + '\n'
             toctree = None
       else:
          process += line + '\n'

   if toctree != None:
      # end directive at end of file
      process += toctree

   return process

def _preprocess_rst_figure(path: str, text: str) -> str:
   """
   scan document for figure directive
   """
   block = None
   
   indent = None  # indent while capturing
   arguments = None # arguments while capturing
   content = None # content while capturing
   figure = None  # simplified
   
   # processed text
   process = ''
   logging.debug("preprocessing figure: "+path)
   for line in text.splitlines():
       # logging.debug('processing:'+line)
       blank = len(line.strip()) == 0
       if block == None:
          match = re.search(r"^(\s*)\.\. figure::\s*((\w|-|\.)*)$", line)
          if match:
             # figure directive started
             block = line + '\n'
             indent = match.group(1)
             image = match.group(2)
             
             content = None
             arguments = {}
             figure = indent + '.. image:: '+image+'\n'
             
             logging.debug("    figure: " + image)
             continue
          else:
             # logging.debug('      scan:'+line)
             process += line + '\n'
             continue
       else:
          indented = len(line) - len(line.lstrip())
          if blank and content == None:
             logging.debug('     blank:'+line)
             # capture content next
             block += line + '\n'
             content = ''
             continue
          elif line.strip()[indented:1] == ':' and content == None:
             logging.debug('   process:'+line)
             # capture arguments
             block += line + '\n'
             (ignore,option,value) = line.split(':',2)
             logging.debug("      "+option+'='+value)
             arguments[option] = value
             continue
          elif indented > len(indent):
             # directive content
             block += line + '\n'
             
             if content == '':
                 logging.debug('   caption:'+line)
                 caption = line.strip()
                 print(caption, caption[0], caption[-1])
                 if caption[0] == '*' and caption[-1] == '*':
                     content = indent + caption
                 else:
                     content = indent + '*'+caption+'*'
             else:
                 logging.debug('   legend:'+line)
                 content += '\n'+indent+line.strip()
             # figure += indent + line.strip() + '\n'
             continue
          else:
             logging.debug('      done:'+line)
             # end directive
             if arguments:
                 logging.debug('      arguments:'+str(arguments))
             if content:
                 logging.debug('      content:'+content)
             
             logging.debug("rst figure:\n"+block)
             logging.debug("rst image:\n"+figure)
             process += figure
             if content:
                 process += content + '\n'

             process += '\n' + line + '\n'
             block = None
             figure = None
             indent = None
             arguments = None
             content = None
             continue

   if block != None:
      # end directive at end of file
      logging.debug("rst figure:\n"+block)
      logging.debug("markdown image:]m"+figure)
      process += figure + '\n'

   return process

def _preprocess_rst_strip(path: str, text: str, directive: str) -> str:
   """
   scan document and strip indicated block directive
   """
   block = None
   process = ''
   for line in text.splitlines():
       if '.. '+directive+'::' in line:
          # directive started
          block = line
          continue

       if block != None:
          if len(line.strip()) == 0:
             block += line
             continue
          if line.strip()[0:1] == ':':
             block += line
             continue
          if line[0:3] == '   ':
             # processing directive
             block += line
          else:
             # end directive
             logging.debug("strip "+directive+":"+block)
             process += '\n' + line + '\n'
             block = None
       else:
          process += line + '\n'

   if block != None:
      # end directive at end of file
      logging.debug("strip "+directive+":"+block)
   
   return process

def postprocess_rst_markdown(md_file: str, md_clean: str):
    """
    Postprocess pandoc generated markdown for mkdocs use.
    """

    with open(md_file, 'r') as markdown:
        text = markdown.read()

    # process pandoc ::: adominitions to mkdocs representation
    if ':::' in text:
        text = _postprocess_pandoc_fenced_divs(md_file, text)


    if "{.title-ref}" in text:
        # some strange thing where `TEXT` is taken to be a wiki link
        text = re.sub(
            r"\[(.*?)\]{\.title-ref}",
            r"``\1``",
            text,
            flags=re.MULTILINE
        )

    # review line by line (skipping fenced code blocks)
    clean = ''
    code = None
    for line in text.splitlines():
       if re.match("^(.*)```", line):
          if code == None:
            code = line + '\n'
          else:
            code += line
            clean += code + '\n'
            code = None
          continue

       # accept code blocks as is
       if code:
          code += line + '\n'
          continue;

       # non-code clean content
       # fix rst#anchor -> md links#anchor
       line = re.sub(
            r"\[(.+?)\]\(((\w|-|/|\.)*)\.rst(#.*?)?\)",
            r"[\1](\2.md\4)",
            line,
            flags=re.MULTILINE
       )

       # Pandoc escapes characters over-aggressively when writing markdown
       # https://github.com/jgm/pandoc/issues/6259
       # <, >, \, `, *, _, [, ], #
       line = line.replace(r'**\`', '**`')
       line = line.replace(r'\`**', '`**')
       line = line.replace(r'\<', '<')
       line = line.replace(r'\>', '>')
       line = line.replace(r'\_', '_')
       line = line.replace(r"\`", "`")
       line = line.replace(r"\'", "'")
       line = line.replace(r'\"', '"')
       line = line.replace(r'\[', '[')
       line = line.replace(r'\]', ']')
       line = line.replace(r'\*', '*')
       line = line.replace(r'\-', '-')
       line = line.replace(r'\|', '|')
       line = line.replace(r'\@', '@')

       clean += line + '\n'

    if code:
       # file ended with a code block
       clean += code

    with open(md_clean,'w') as markdown:
        markdown.write(clean)

def _postprocess_pandoc_fenced_divs(md_file:str, text: str) -> str:
   # scan document for pandoc fenced div info, warnings, ...
   admonition = False
   type = None
   ident = ''
   title = None
   note = None
   process = ''
   for line in text.splitlines():
       match = re.search(r"^(\s*):::\s*(\w*)$", line)
       if match and admonition == False:
          # admonition started
          # https://squidfunk.github.io/mkdocs-material/reference/admonitions/
          admonition = True
          indent = match.group(1)
          type = match.group(2)

          # sphinx-build admonition mappings
          # https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html#rst-directives
          if type == 'attention':
             type = 'info'
          if type == 'caution':
             type = 'warning'
          if type == 'danger':
             type = 'danger'
          if type == 'error':
             type = 'failure'
          if type == 'hint':
             type = 'tip'
          if type == 'important':
             type = 'info'
          if type == 'note':
             type = 'note'
          if type == 'tip':
             type = 'tip'
          if type == 'warning':
             type = 'warning'

          # sphinx-build directives mapping to fenced blogs
          # https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html
          if type == 'todo':
             type = 'info'
             title = 'Todo'
             note = ''
          if type == 'admonition':
             type = 'abstract'
             title = ''

          if type == 'deprecated':
             type = 'warning'
             title = 'Deprecated'
             note = ''
          if type == 'seealso':
             type = 'info'
             title = 'See Also'
             note = ''
          if type == 'versionadded':
             type = 'info'
             title = 'Version Added'
             note = ''
          if type == 'versionchanged':
             type = 'info'
             title = 'Version Changed'
             note = ''
          if type == 'versionchanged':
             type = 'info'
             title = 'Version Changed'
             note = ''
          log("process:'"+line+"'")
          log('start:',type," title:", title)
          continue

       if admonition:
          # processing fenced div
          log("process:'"+line+"'")

          if match and match.group(2) == 'title':
             # start title processing, next line title
             title = ''
             log("start title")
             continue

          if title == '':
             title = line.strip() # title obtained
             log("title",title)
             if type == 'abstract':
                # .. admonition:: Explore does not use seperate ::: marker between title and note
                note = ''
             continue

          if match and note == None:
             # start note processing, next content is note
             note = ''
             log("start note")
             continue

          if match:
             # processing fenced div
             log("fenced div")
             log("  type:",type)
             log("  title:",title)
             log("  note:",note)

             process += indent+'!!! '+type

             if title != None and title.lower() != type.lower():
               process += ' "' + title + '"'

             process += "\n\n"
             for content in note.splitlines():
                 process += '    '+content+'\n'

             process += "\n"

             admonition = False
             type = None
             ident = ''
             title = None
             note = None
             continue

          if note != None:
             if note == '' and line.strip() == '':
                # skip initial blank line
                continue
             note += line + '\n'
             log("note:"+line)
             continue

          # unexpected
          print("unexpected:")
          print("  admonition",admonition)
          print("  type",type)
          print("  title",title)
          print("  note",note)
          print("  line",line)
          print("  process",len(process))
          print()
          print(process)
          raise ValueError('unclear what to process '+str(type)+" "+str(title)+"\n"+md_file)

       else:
          process += line + '\n'

   if admonition:
      # fenced div was at end of file
      print("unexpected:")
      print("  admonition",admonition)
      print("  type",type)
      print("  title",title)
      print("  note",note)
      raise ValueError('Expected ::: to end fence dive '+str(type)+' '+str(title)+' '+str(note)+"\n"+md_file)

   return process

def log(*args):
   if False:
      message = ''
      for value in args:
         message += str(value) + ' '
      print(message)

def convert_markdown(md_file: str) -> str:
    """
    Use pandoc to convert markdown file to html file for translation.
    :param md_file: Markdown file path
    :return: html file path
    """
    if not os.path.exists(md_file):
       raise FileNotFoundError(errno.ENOENT, f"Markdown file does not exist at location:", md_file)

    if not md_file[-3:] == '.md':
       raise FileNotFoundError(errno.ENOENT, f"Markdown 'md' extension required:", md_file)

    upload_folder = config['upload_folder']

    path = re.sub("^docs/",upload_folder+'/', md_file)
    path = path.replace(".en.md",".en.html")
    path = path.replace(".md",".html")
    html_file = path

    html_dir = os.path.dirname(path)
    if not os.path.exists(html_dir):
       print("Translation directory:",html_dir)
       os.makedirs(html_dir)

    md_prep = re.sub(r"\.html",r".prep.md", path)

    logging.debug("Preprocessing '"+md_file+"' to '"+md_prep+"'")
    preprocess_markdown(md_file,md_prep)

    logging.debug("Converting '"+md_prep+"' to '"+html_file+"'")
    # pandoc --from gfm --to html -o index.en.html index.md
    completed = subprocess.run(["pandoc",
       "--from", md_extensions_from,
       "--to","html",
       "--wrap=none",
       "--eol=lf",
       "-o", html_file,
       md_prep
    ])
    if completed.returncode != 0:
        print(completed)

    if not os.path.exists(html_file):
       raise FileNotFoundError(errno.ENOENT, f"Pandoc did not create html file:", html_file)

    return html_file


def preprocess_markdown(md_file:str, md_prep: str) -> str:
    with open(md_file, 'r') as file:
        text = file.read()

    clean = ''
    code = ''
    admonition = None

    # handle notes as pandoc fenced_divs
    for line in text.splitlines():
        # phase 1: code-block pre-processing
        #
        # cause pandoc #markdown or #text to force to fenced codeblocks (rather than indent)
        if re.match("^```", line):
          if len(code) > 0:
            # print("code-end: '"+line+"'")
            # end code block (so no processing)
            code = ''

          else:
            # print("code-block: '" + line +"'")
            line = re.sub(
                 r"^```(\S+)$",
                 r"```#\1",
                 line,
                 flags=re.MULTILINE
            )
            line = re.sub(
                 r"^```$",
                 r"```#text",
                 line,
                 flags=re.MULTILINE
            )
            code = line[4:]

        # phase 2: process blocks
        if not admonition:
           if '!!! ' in line:
               # print('admonition start  : "'+line+'"')
               admonition = line
           else:
               clean += line + '\n'
        else:
           indent = admonition.index('!!! ')
           padding = admonition[0:indent]

           if len(line) == 0:
               if '\n' in admonition:
                   # print('admonition blank  : "'+line+'"')
                   admonition += line+"\n"
               else:
                   # print('admonition skip   : "'+line+'"')
                   admonition += "\n"
           elif line[0:indent].isspace():
               # print('admonition content: "'+line+'"')
               # use indent level to gather admonition contents
               admonition += padding+line[indent+4:]+'\n'
           else:
               # print('admonition end    : "'+line+'"')
               # outdent admonition completed
               first_newline = admonition.index('\n')
               last_newline = admonition.rindex('\n')

               title = admonition[indent+4:first_newline]
               contents = admonition[first_newline:last_newline]

               # output as pandoc fenced_divs
               clean += padding+"::: "+title
               clean += contents
               clean += padding+":::\n\n"

               # remember to output line that breaks indent level
               admonition = None

               clean += line + '\n'

    with open(md_prep,'w') as markdown:
        markdown.write(clean)

def convert_html(html_file: str) -> str:
    """
    Use pandoc to convert markdown file to html file for translation.
    :param html_file: HTML file path
    :return: md file path
    """
    if not os.path.exists(html_file):
       raise FileNotFoundError(errno.ENOENT, f"HTML file does not exist at location:", html_file)

    if not html_file[-5:] == '.html':
       raise FileNotFoundError(errno.ENOENT, f"HTML '.html' extension required:", html_file)

    # prep html file for conversion
    html_tmp_file = html_file[0:-5] + '.tmp.html'

    preprocess_html(html_file, html_tmp_file)
    if not os.path.exists(html_tmp_file):
       raise FileNotFoundError(errno.ENOENT, f"Did not create preprocessed html file:", html_tmp_file)

    if html_file[:-8] == '.fr.html':
       md_file = html_file[0:-8] + '.fr.md'
    if html_file[:-5] == '.html':
       md_file = html_file[0:-8] + '.md'
    else:
       md_file = html_file[0:-5] + '.md'

    md_tmp_file = md_file[0:-3]+".tmp.md"

    completed = subprocess.run(["pandoc",
       "--from","html",
       "--to", md_extensions_to,
       "--wrap=none",
       "--eol=lf",
       "-o", md_tmp_file,
       html_tmp_file
    ])
    print(completed)

    if not os.path.exists(md_tmp_file):
       raise FileNotFoundError(errno.ENOENT, f"Pandoc did not create temporary md file:", tmp_file)

    postprocess_markdown(md_tmp_file, md_file)
    if not os.path.exists(md_file):
       raise FileNotFoundError(errno.ENOENT, f"Did not create postprocessed md file:", md_file)

    return md_file

def preprocess_html(html_file: str, html_clean: str):
    with open(html_file, 'r') as html:
        data = html.read()

    # Fix image captions
    #
    #     ![Search field](img/search.png) *Champ de recherche*
    #
    # Clean:
    #
    #    ![Search field](img/search.png)
    #    *Champ de recherche*
    #
    clean = re.sub(
        r'^<p>:: : note ',
        r'<div class="note">\n<p>',
        data,
        flags=re.MULTILINE
    )
    clean = re.sub(
        r'^<p>:: :</p>',
        r'</div>',
        clean,
        flags=re.MULTILINE
    )
    # Fix deepl not respecting <pre><code> blogs using CDATA
    clean = re.sub(
        r'<code><!\[CDATA\[',
        r'<code>',
        clean,
        flags=re.MULTILINE
    )
    clean = re.sub(
        r'\]\]></code>',
        r'</code>',
        clean,
        flags=re.MULTILINE
    )
    with open(html_clean,'w') as html:
        html.write(clean)

def postprocess_markdown(md_file: str, md_clean: str):
    with open(md_file, 'r') as markdown:
        data = markdown.read()

    # Fix image captions
    #
    #     ![Search field](img/search.png) *Champ de recherche*
    #
    # Clean:
    #
    #    ![Search field](img/search.png)
    #    *Champ de recherche*
    #
#     data = re.sub(
#         r"^(\s*)\!\[(.*)\]\((.*)\)\s\*(.*)\*$",
#         r"\1![\2](\3)\1*\4*",
#         data,
#         flags=re.MULTILINE
#     )
    # fix icons
    data = re.sub(
        r":(fontawesome-\S*)\s:",
        r":\1:",
        data,
        flags=re.MULTILINE
    )
    # fix fence text blocks
    data = re.sub(
        r'^``` #text$',
        r'```',
        data,
        flags=re.MULTILINE
    )
    # fix fenced code blocks
    data = re.sub(
        r'^``` #(.+)$',
        r'```\1',
        data,
        flags=re.MULTILINE
    )
    with open(md_clean,'w') as markdown:
        markdown.write(data)

def deepl_document(en_html:str, fr_html:str):
    """
    Submit english html file to deepl for translation.
    :param en_html: English html file
    :param fr_html: French html file
    :return: status
    """

   
    if not os.path.exists(en_html):
       raise FileNotFoundError(errno.ENOENT, f"HTML file does not exist at location:", en_html)

    AUTH = load_auth()

    # prep html file for conversion
    translate_tmp_file = en_html[0:-5] + '.tmp.html'
    print("Preprocssing",en_html,"to",translate_tmp_file)

    preprocess_translate(en_html, translate_tmp_file)

    translator = deepl.Translator(AUTH)

    try:
        # Using translate_document_from_filepath() with file paths
        translator.translate_document_from_filepath(
            translate_tmp_file,
            fr_html,
            source_lang='EN',
            target_lang="FR",
            formality="more"
        )

    except deepl.DocumentTranslationException as error:
        # If an error occurs during document translation after the document was
        # already uploaded, a DocumentTranslationException is raised. The
        # document_handle property contains the document handle that may be used to
        # later retrieve the document from the server, or contact DeepL support.
        doc_id = error.document_handle.id
        doc_key = error.document_handle.key
        print(f"Error after uploading ${error}, id: ${doc_id} key: ${doc_key}")

    except deepl.DeepLException as error:
        # Errors during upload raise a DeepLException
        print(error)

    if not os.path.exists(fr_html):
       raise FileNotFoundError(errno.ENOENT, f"Deepl did not create md file:", fr_html)

    return

def preprocess_translate(html_file: str, html_clean: str):
    with open(html_file, 'r') as html:
        data = html.read()

    # Fix deepl not respecting <pre><code> blogs using CDATA
    data = re.sub(
        r'<code>',
        r'<code><![CDATA[',
        data,
        flags=re.MULTILINE
    )
    data = re.sub(
        r'</code>',
        r']]></code>',
        data,
        flags=re.MULTILINE
    )
    with open(html_clean,'w') as html:
        html.write(data)